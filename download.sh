# Function to extract the extension if exist
# from a string
# argument: string
# 
# If no extension is found default extension is
# html 
function get_ext()
{
	local link=$1
	local filename=$(basename -- "$link")
	local extension="${filename##*.}"

	if [[ extension == "" ]]
	then
		extension=".html"
	fi
}


# argument: path to the file containing multiple webpages
# to be downloaded
# 
# E.g. if the file contains 5 links. This will parallely download
# (max 16) these links as files with names 1, 2, 3, 4, 5
# 
# A link if not connected in 5 seconds is skipped.
# 
# Dependency: aria2c
function download()
{
	local dir=$(dirname "$1")
	local refer_file=$(basename "$1")

	cd "$dir"
	rm -f log.txt uri.txt
	count=0

	while read link
	do 
		count=$((count+1))
		echo "$count" "$link" >> log.txt
		echo -e "$link" "\n\tout=$count" >> uri.txt
	done < "$refer_file"
	
	aria2c -c -x 16 -s 16 -q --connect-timeout=5 -i uri.txt
	exit_code=$?

	rm uri.txt
	cd - 
	return $exit_code
}


# Argument: path to the folder containing downloaded webpages
# with files as 1, 2, 3, 4 ... etc
# 
# This function tries to find and apply correct extension to each
# file based on mime-type
function auto_extension()
{
	echo "Applying Correct Extensions..."
	local dir="$1"
	cd "$dir"
	for each in *
	do
		local mime_type=$(file --mime-type $each | awk '{print $2}')
		local ext=$(grep -v '^\#' /etc/mime.types | grep -w "$mime_type" | head -n 1 | awk '{ print$2}')
		if [[ ! -z $ext ]]
		then
	    	mv "$each" "${each%%.*}.${ext,,}"
	    fi
	done
	cd -
}

# Argument: path to the directory generated by wiki_references.py 
#
# Downloads all the links in all the references.txt in the respective
# folder
function main()
{
	local download_dir=$1

	num_file=0
	find "$download_dir" -iname "*references.txt" | sort > "list_of_ref.txt"
	while read file
	do
		num_file=$((num_file+1))
		echo $num_file":" $file
		download "$file"
		auto_extension "$(dirname "$file")"
		test $? -eq 7 && break
	done < "list_of_ref.txt"

	rm "list_of_ref.txt"
}

main "$@"
